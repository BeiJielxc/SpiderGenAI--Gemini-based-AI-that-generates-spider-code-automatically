"""
PyGen éªŒè¯å™¨æ¨¡å— - ä»£ç é™æ€æ£€æŸ¥ + è¾“å‡ºç»“æ„éªŒè¯

æä¾›ä¸¤å±‚éªŒè¯ï¼š
1. StaticCodeValidator: åœ¨ä»£ç æ‰§è¡Œå‰æ£€æŸ¥å¸¸è§é”™è¯¯æ¨¡å¼
2. OutputValidator: éªŒè¯çˆ¬è™«è¾“å‡ºçš„ JSON æ•°æ®ç»“æ„

ä½¿ç”¨æ–¹å¼ï¼š
    from validator import StaticCodeValidator, OutputValidator, CrawlRecord
    
    # é™æ€æ£€æŸ¥
    validator = StaticCodeValidator()
    issues = validator.validate(code)
    
    # è¾“å‡ºéªŒè¯
    output_validator = OutputValidator()
    is_valid, errors = output_validator.validate_output(json_data)
"""

import re
import ast
from typing import List, Dict, Any, Tuple, Optional
from dataclasses import dataclass, field
from enum import Enum
from pydantic import BaseModel, field_validator, ValidationError
from datetime import datetime


# ============================================================================
# Pydantic è¾“å‡ºæ¨¡å‹
# ============================================================================

class CrawlRecord(BaseModel):
    """å•æ¡çˆ¬å–è®°å½•çš„æ•°æ®æ¨¡å‹"""
    id: Optional[str] = None
    name: str
    date: str = ""
    downloadUrl: str
    fileType: str = "pdf"
    
    @field_validator('name')
    @classmethod
    def name_not_empty(cls, v: str) -> str:
        if not v or len(v.strip()) < 2:
            raise ValueError('name å­—æ®µä¸èƒ½ä¸ºç©ºæˆ–è¿‡çŸ­ï¼ˆè‡³å°‘2ä¸ªå­—ç¬¦ï¼‰')
        return v.strip()
    
    @field_validator('downloadUrl')
    @classmethod
    def url_valid(cls, v: str) -> str:
        if not v:
            raise ValueError('downloadUrl ä¸èƒ½ä¸ºç©º')
        if not v.startswith(('http://', 'https://', '//')):
            raise ValueError(f'downloadUrl å¿…é¡»æ˜¯æœ‰æ•ˆURLï¼Œå½“å‰å€¼: {v[:50]}...')
        return v
    
    @field_validator('date')
    @classmethod
    def date_format_valid(cls, v: str) -> str:
        if not v:
            return ""  # å…è®¸ç©ºæ—¥æœŸ
        # æ ‡å‡†åŒ–å¸¸è§æ—¥æœŸæ ¼å¼
        v = v.replace('/', '-').replace('.', '-')
        # æ£€æŸ¥åŸºæœ¬æ ¼å¼
        if not re.match(r'^\d{4}-\d{1,2}-\d{1,2}', v):
            raise ValueError(f'date æ ¼å¼æ— æ•ˆï¼Œåº”ä¸º YYYY-MM-DDï¼Œå½“å‰å€¼: {v}')
        return v


class CrawlOutput(BaseModel):
    """çˆ¬å–è¾“å‡ºçš„å®Œæ•´æ•°æ®æ¨¡å‹"""
    total: int
    crawlTime: str
    reports: List[CrawlRecord]
    
    @field_validator('total')
    @classmethod
    def total_must_be_positive(cls, v: int) -> int:
        if v < 0:
            raise ValueError('total ä¸èƒ½ä¸ºè´Ÿæ•°')
        return v
    
    @field_validator('reports')
    @classmethod
    def reports_not_empty(cls, v: List[CrawlRecord]) -> List[CrawlRecord]:
        if len(v) == 0:
            raise ValueError('reports åˆ—è¡¨ä¸èƒ½ä¸ºç©º')
        return v


# ============================================================================
# é™æ€ä»£ç éªŒè¯å™¨
# ============================================================================

class IssueSeverity(Enum):
    """é—®é¢˜ä¸¥é‡ç¨‹åº¦"""
    ERROR = "error"       # å¿…é¡»ä¿®å¤
    WARNING = "warning"   # å»ºè®®ä¿®å¤
    INFO = "info"         # æç¤ºä¿¡æ¯


@dataclass
class CodeIssue:
    """ä»£ç é—®é¢˜"""
    code: str                    # é—®é¢˜ä»£ç ï¼ˆå¦‚ ERR_001ï¼‰
    severity: IssueSeverity      # ä¸¥é‡ç¨‹åº¦
    message: str                 # é—®é¢˜æè¿°
    line_number: Optional[int] = None   # è¡Œå·ï¼ˆå¦‚æœå¯æ£€æµ‹ï¼‰
    suggestion: str = ""         # ä¿®å¤å»ºè®®


class StaticCodeValidator:
    """
    é™æ€ä»£ç éªŒè¯å™¨ - åœ¨è¿è¡Œå‰æ£€æµ‹å¸¸è§é”™è¯¯æ¨¡å¼ï¼ˆæ”¯æŒä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼‰
    
    æ£€æŸ¥é¡¹ï¼š
    1. ç¡¬ç¼–ç åˆ—ç´¢å¼• (tds[N]) - ç»“åˆ page_structure æ™ºèƒ½åˆ¤æ–­
    2. é“¾å¼è°ƒç”¨ç©ºæŒ‡é’ˆ (find().find_all())
    3. è¾“å‡ºå­—æ®µåé”™è¯¯ (title vs name)
    4. SPA é¡µé¢ç”¨ requests - ç»“åˆ spaHints æ™ºèƒ½åˆ¤æ–­
    5. æ—¥æœŸæå–ç­–ç•¥é—®é¢˜ - ç»“åˆ dateColumnHints æ™ºèƒ½åˆ¤æ–­
    
    v2.0 æ›´æ–°ï¼šæ”¯æŒ page_structure ä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼Œé¿å…è¯¯ä¼¤æ­£ç¡®ä»£ç 
    """
    
    def __init__(self):
        self.issues: List[CodeIssue] = []
        self.page_structure: Optional[Dict[str, Any]] = None
        
    def validate(self, code: str, page_structure: Optional[Dict[str, Any]] = None) -> List[CodeIssue]:
        """
        éªŒè¯ä»£ç ï¼Œè¿”å›å‘ç°çš„é—®é¢˜åˆ—è¡¨ï¼ˆæ”¯æŒä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼‰
        
        Args:
            code: Python ä»£ç å­—ç¬¦ä¸²
            page_structure: é¡µé¢ç»“æ„ä¿¡æ¯ï¼ˆæ¥è‡ª browser.analyze_page_structure()ï¼‰
                           åŒ…å«è¡¨æ ¼åˆ—æ•°ã€æ—¥æœŸåˆ—ä½ç½®ã€SPA çº¿ç´¢ç­‰
            
        Returns:
            é—®é¢˜åˆ—è¡¨
        """
        self.issues = []
        self.page_structure = page_structure

        # 0) è¯­æ³•/ç¼–è¯‘æœŸæ£€æŸ¥ï¼ˆå¿…é¡»æœ€å…ˆåšï¼‰
        # ä¾‹å¦‚ï¼šSyntaxError: name 'X' is used prior to global declaration
        # è¿™ç±»é—®é¢˜ä»…é æ­£åˆ™è§„åˆ™æ— æ³•è¦†ç›–ï¼Œä¸”è¿è¡Œå‰å¿…é¡»æ‹¦æˆªã€‚
        if not self._check_python_syntax(code):
            # è¯­æ³•éƒ½ä¸é€šè¿‡ï¼Œåç»­è§„åˆ™æ£€æŸ¥æ²¡æœ‰æ„ä¹‰
            return self.issues
        
        # æ‰§è¡Œå„é¡¹æ£€æŸ¥ï¼ˆéƒ¨åˆ†æ£€æŸ¥ä¼šä½¿ç”¨ self.page_structure è¿›è¡Œæ™ºèƒ½åˆ¤æ–­ï¼‰
        self._check_hardcoded_column_index(code)
        self._check_chained_find_calls(code)
        self._check_output_field_names(code)
        self._check_spa_requests(code)
        self._check_date_from_title(code)
        self._check_keeps_undated_records(code)
        self._check_single_page_dates(code)
        self._check_missing_date_extraction(code)
        self._check_unicode_print_chars(code)
        
        return self.issues
    
    def get_page_structure_summary(self) -> str:
        """
        ç”Ÿæˆé¡µé¢ç»“æ„æ‘˜è¦ï¼ˆç”¨äº LLM ä¿®å¤æ—¶æä¾›ä¸Šä¸‹æ–‡ï¼‰
        
        Returns:
            é¡µé¢ç»“æ„çš„æ–‡æœ¬æ‘˜è¦
        """
        if not self.page_structure:
            return ""
        
        lines = ["## é¡µé¢ç»“æ„å‚è€ƒï¼ˆå¸®åŠ©ä½ æ­£ç¡®ä¿®å¤ï¼‰\n"]
        
        # è¡¨æ ¼ä¿¡æ¯
        tables = self.page_structure.get('tables', [])
        if tables:
            table = tables[0]  # å–ç¬¬ä¸€ä¸ªè¡¨æ ¼
            lines.append(f"- è¡¨æ ¼åˆ—æ•°: {table.get('columnCount', 'æœªçŸ¥')}")
            headers = table.get('headers', [])
            if headers:
                lines.append(f"- è¡¨å¤´: {headers[:8]}")
            
            # æ—¥æœŸåˆ—ä¿¡æ¯ï¼ˆå…³é”®ï¼ï¼‰
            date_indices = table.get('dateColumnIndices', [])
            date_hints = table.get('dateColumnHints', [])
            if date_indices:
                lines.append(f"- **æ—¥æœŸåˆ—ä½ç½®**: ç´¢å¼• {date_indices} (ä»0å¼€å§‹)")
                for hint in date_hints[:3]:
                    lines.append(f"  - ç¬¬{hint.get('columnIndex')}åˆ—ã€Œ{hint.get('headerText', '?')}ã€æ£€æµ‹åˆ°{hint.get('occurrences', '?')}æ¬¡æ—¥æœŸ")
            else:
                lines.append("- æ—¥æœŸåˆ—ä½ç½®: æœªæ£€æµ‹åˆ°æ˜ç¡®çš„æ—¥æœŸåˆ—")
            
            # ä¸‹è½½é“¾æ¥åˆ—
            download_indices = table.get('downloadColumnIndices', [])
            if download_indices:
                lines.append(f"- ä¸‹è½½é“¾æ¥åˆ—: ç´¢å¼• {download_indices}")
            
            # é¦–è¡Œé¢„è§ˆ
            first_row = table.get('firstRowPreview', [])
            if first_row:
                lines.append(f"- é¦–è¡Œæ•°æ®é¢„è§ˆ: {first_row[:6]}")
        
        # SPA çº¿ç´¢
        spa_hints = self.page_structure.get('spaHints', {})
        if spa_hints:
            if spa_hints.get('hasHashRoute') or spa_hints.get('hasAppRoot'):
                lines.append(f"- **SPA é¡µé¢**: hasHashRoute={spa_hints.get('hasHashRoute')}, hasAppRoot={spa_hints.get('hasAppRoot')}")
        
        # æ—¥æœŸå…ƒç´ 
        date_elements = self.page_structure.get('dateElements', [])
        if date_elements:
            lines.append(f"- é¡µé¢ä¸­æ£€æµ‹åˆ° {len(date_elements)} ä¸ªæ—¥æœŸå…ƒç´ ")
            for de in date_elements[:3]:
                lines.append(f"  - ã€Œ{de.get('dateValue')}ã€ä½äº {de.get('selector')}")
        
        return "\n".join(lines)

    def _check_python_syntax(self, code: str) -> bool:
        """æ£€æŸ¥ Python è¯­æ³•æ˜¯å¦å¯ç¼–è¯‘ï¼ˆç¼–è¯‘æœŸé”™è¯¯åº”ç›´æ¥æ‹¦æˆªï¼‰"""
        try:
            # compile æ¯” ast.parse æ›´è´´è¿‘çœŸå®æ‰§è¡Œï¼ˆåŒæ ·èƒ½æ•è· SyntaxError/IndentationErrorï¼‰
            compile(code, "<pygen_generated>", "exec")
            return True
        except SyntaxError as e:
            # e.lineno / e.offset / e.text å¯èƒ½ä¸º None
            line_no = getattr(e, "lineno", None)
            msg = getattr(e, "msg", None) or str(e)
            detail = msg
            if line_no:
                detail = f"{msg}ï¼ˆè¡Œ {line_no}ï¼‰"
            self.issues.append(CodeIssue(
                code="ERR_SYNTAX",
                severity=IssueSeverity.ERROR,
                message=f"Python è¯­æ³•é”™è¯¯: {detail}",
                line_number=line_no,
                suggestion="ä¿®å¤è¯­æ³•/ç¼©è¿›/å…¨å±€å£°æ˜é”™è¯¯åå†è¿è¡Œï¼ˆä¾‹å¦‚ global å¿…é¡»åœ¨å‡½æ•°å†…é¦–æ¬¡ä½¿ç”¨å˜é‡ä¹‹å‰å£°æ˜ï¼‰"
            ))
            return False
        except Exception as e:
            # æå°‘æ•°æƒ…å†µä¸‹ compile å¯èƒ½æŠ›å‡ºå…¶ä»–å¼‚å¸¸ï¼ˆä¿å®ˆå¤„ç†ä¸ºé”™è¯¯ï¼‰
            self.issues.append(CodeIssue(
                code="ERR_SYNTAX",
                severity=IssueSeverity.ERROR,
                message=f"ä»£ç æ— æ³•ç¼–è¯‘: {str(e)}",
                suggestion="è¯·æ£€æŸ¥ç”Ÿæˆä»£ç æ˜¯å¦åŒ…å«ä¸å®Œæ•´çš„è¯­å¥/éæ³•å­—ç¬¦"
            ))
            return False
    
    def has_errors(self) -> bool:
        """æ˜¯å¦å­˜åœ¨å¿…é¡»ä¿®å¤çš„é”™è¯¯"""
        return any(i.severity == IssueSeverity.ERROR for i in self.issues)
    
    def has_warnings(self) -> bool:
        """æ˜¯å¦å­˜åœ¨è­¦å‘Š"""
        return any(i.severity == IssueSeverity.WARNING for i in self.issues)
    
    def get_summary(self) -> str:
        """è·å–é—®é¢˜æ‘˜è¦"""
        if not self.issues:
            return "âœ… ä»£ç æ£€æŸ¥é€šè¿‡ï¼Œæœªå‘ç°é—®é¢˜"
        
        errors = [i for i in self.issues if i.severity == IssueSeverity.ERROR]
        warnings = [i for i in self.issues if i.severity == IssueSeverity.WARNING]
        
        lines = []
        if errors:
            lines.append(f"ğŸ”´ å‘ç° {len(errors)} ä¸ªé”™è¯¯ï¼ˆå¿…é¡»ä¿®å¤ï¼‰:")
            for e in errors:
                lines.append(f"  - [{e.code}] {e.message}")
        if warnings:
            lines.append(f"ğŸŸ¡ å‘ç° {len(warnings)} ä¸ªè­¦å‘Šï¼ˆå»ºè®®ä¿®å¤ï¼‰:")
            for w in warnings:
                lines.append(f"  - [{w.code}] {w.message}")
        
        return "\n".join(lines)
    
    def get_repair_prompt(self) -> str:
        """ç”Ÿæˆç”¨äº LLM ä¿®å¤çš„æç¤º"""
        if not self.issues:
            return ""
        
        lines = ["ã€ä»£ç æ£€æŸ¥å‘ç°ä»¥ä¸‹é—®é¢˜ï¼Œè¯·ä¿®å¤ã€‘\n"]
        
        for issue in self.issues:
            severity_icon = "ğŸ”´" if issue.severity == IssueSeverity.ERROR else "ğŸŸ¡"
            lines.append(f"{severity_icon} [{issue.code}] {issue.message}")
            if issue.suggestion:
                lines.append(f"   ä¿®å¤å»ºè®®: {issue.suggestion}")
            lines.append("")
        
        lines.append("è¯·ä¿®æ­£ä»¥ä¸Šé—®é¢˜å¹¶é‡æ–°ç”Ÿæˆå®Œæ•´çš„ Python ä»£ç ã€‚")
        return "\n".join(lines)
    
    # -------------------------------------------------------------------------
    # å…·ä½“æ£€æŸ¥æ–¹æ³•
    # -------------------------------------------------------------------------
    
    def _check_hardcoded_column_index(self, code: str) -> None:
        """
        æ£€æŸ¥ç¡¬ç¼–ç åˆ—ç´¢å¼•ï¼ˆä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰ˆæœ¬ï¼‰
        
        æ”¹è¿›ï¼šç»“åˆ page_structure ä¸­çš„ dateColumnIndices åˆ¤æ–­ç¡¬ç¼–ç æ˜¯å¦æ­£ç¡®
        - å¦‚æœç¡¬ç¼–ç çš„åˆ—ç´¢å¼•ç¡®å®æ˜¯æ—¥æœŸåˆ—ï¼Œåˆ™ä¸æŠ¥é”™
        - å¦‚æœç¡¬ç¼–ç çš„åˆ—ç´¢å¼•ä¸æ˜¯æ—¥æœŸåˆ—ï¼Œåˆ™æŠ¥è­¦å‘Šå¹¶æç¤ºæ­£ç¡®ä½ç½®
        - å¦‚æœæ²¡æœ‰ page_structureï¼Œé™çº§ä¸ºè­¦å‘Šï¼ˆè€Œéé”™è¯¯ï¼‰
        """
        # å¦‚æœä½¿ç”¨äº†æ™ºèƒ½æ—¥æœŸæ‰«æå‡½æ•°ï¼Œè·³è¿‡æ£€æŸ¥
        if "_pygen_smart_find_date_in_row" in code:
            return
        
        code_lower = code.lower()
        if "date" not in code_lower:
            return  # å¦‚æœä»£ç ä¸­æ²¡æœ‰ date ç›¸å…³å†…å®¹ï¼Œè·³è¿‡
        
        # æå–ä»£ç ä¸­æ‰€æœ‰ tds[N] æˆ– cols[N] çš„ä½¿ç”¨
        index_pattern = re.compile(r'(tds|cols)\[(\d+)\]')
        matches = list(index_pattern.finditer(code))
        
        if not matches:
            return
        
        # è·å–é¡µé¢ç»“æ„ä¸­çš„æ—¥æœŸåˆ—ä¿¡æ¯
        date_col_indices = []
        column_count = None
        headers = []
        
        if self.page_structure and self.page_structure.get('tables'):
            table = self.page_structure['tables'][0]
            date_col_indices = table.get('dateColumnIndices', [])
            column_count = table.get('columnCount')
            headers = table.get('headers', [])
        
        for match in matches:
            var_name = match.group(1)  # tds æˆ– cols
            col_idx = int(match.group(2))
            
            # æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦ä¸æ—¥æœŸç›¸å…³ï¼ˆå‰å50å­—ç¬¦ï¼‰
            start = max(0, match.start() - 50)
            end = min(len(code), match.end() + 50)
            context = code[start:end].lower()
            
            if 'date' not in context:
                continue  # ä¸æ˜¯æ—¥æœŸæå–ï¼Œè·³è¿‡
            
            # æœ‰ page_structure æ—¶è¿›è¡Œæ™ºèƒ½æ£€æŸ¥
            if self.page_structure and self.page_structure.get('tables'):
                # æ£€æŸ¥1ï¼šç´¢å¼•æ˜¯å¦è¶Šç•Œï¼Ÿ
                if column_count and col_idx >= column_count:
                    self.issues.append(CodeIssue(
                        code="ERR_001",
                        severity=IssueSeverity.ERROR,
                        message=f"åˆ—ç´¢å¼•è¶Šç•Œï¼š{var_name}[{col_idx}]ï¼Œè¡¨æ ¼åªæœ‰ {column_count} åˆ—ï¼ˆç´¢å¼•0-{column_count-1}ï¼‰",
                        suggestion=f"è¯·æ£€æŸ¥åˆ—ç´¢å¼•æ˜¯å¦æ­£ç¡®ï¼Œæ—¥æœŸåˆ—ä½ç½®: {date_col_indices}"
                    ))
                    return
                
                # æ£€æŸ¥2ï¼šè¿™åˆ—æ˜¯å¦æ˜¯æ—¥æœŸåˆ—ï¼Ÿ
                if date_col_indices:
                    if col_idx in date_col_indices:
                        # âœ… æ­£ç¡®ï¼è¿™åˆ—ç¡®å®æ˜¯æ—¥æœŸåˆ—ï¼Œä¸æŠ¥é”™
                        # å¯ä»¥æ·»åŠ ä¸€ä¸ª INFO çº§åˆ«çš„ç¡®è®¤
                        pass
                    else:
                        # âš ï¸ è¿™åˆ—ä¸æ˜¯æ—¥æœŸåˆ—ï¼ŒæŠ¥è­¦å‘Š
                        header_name = headers[col_idx] if col_idx < len(headers) else '?'
                        correct_cols = [f"ç´¢å¼•{i}ã€Œ{headers[i] if i < len(headers) else '?'}ã€" 
                                       for i in date_col_indices]
                        self.issues.append(CodeIssue(
                            code="ERR_001",
                            severity=IssueSeverity.WARNING,
                            message=f"{var_name}[{col_idx}] å¯¹åº”åˆ—ã€Œ{header_name}ã€ï¼Œä½†æ£€æµ‹åˆ°çš„æ—¥æœŸåˆ—æ˜¯: {', '.join(correct_cols)}",
                            suggestion=f"å»ºè®®æ”¹ä¸º {var_name}[{date_col_indices[0]}] æˆ–ä½¿ç”¨ _pygen_smart_find_date_in_row æ™ºèƒ½æ‰«æ"
                        ))
                        return
                else:
                    # è¡¨æ ¼ä¸­æ²¡æœ‰æ£€æµ‹åˆ°æ—¥æœŸåˆ—ï¼Œç»™å‡ºæç¤º
                    self.issues.append(CodeIssue(
                        code="ERR_001",
                        severity=IssueSeverity.INFO,
                        message=f"ä½¿ç”¨äº† {var_name}[{col_idx}] æå–æ—¥æœŸï¼Œä½†é¡µé¢ç»“æ„ä¸­æœªæ£€æµ‹åˆ°æ˜ç¡®çš„æ—¥æœŸåˆ—",
                        suggestion="å¦‚æœè¡¨æ ¼ç»“æ„å›ºå®šï¼Œç¡¬ç¼–ç å¯èƒ½æ˜¯æ­£ç¡®çš„ï¼›å¦åˆ™å»ºè®®ä½¿ç”¨æ™ºèƒ½æ‰«æ"
                    ))
                    return
            else:
                # æ²¡æœ‰ page_structureï¼Œé™çº§ä¸ºè­¦å‘Šï¼ˆè€Œéé”™è¯¯ï¼‰ï¼Œé¿å…è¯¯ä¼¤
                self.issues.append(CodeIssue(
                    code="ERR_001",
                    severity=IssueSeverity.WARNING,
                    message=f"æ£€æµ‹åˆ°ç¡¬ç¼–ç åˆ—ç´¢å¼• {var_name}[{col_idx}] æå–æ—¥æœŸï¼Œæ— æ³•éªŒè¯æ˜¯å¦æ­£ç¡®",
                    suggestion="å»ºè®®ä½¿ç”¨ _pygen_smart_find_date_in_row_bs4(tds) æ™ºèƒ½æ‰«æï¼Œæˆ–ç¡®è®¤åˆ—ç´¢å¼•ä¸ç›®æ ‡ç½‘ç«™è¡¨æ ¼ç»“æ„åŒ¹é…"
                ))
                return
    
    def _check_chained_find_calls(self, code: str) -> None:
        """æ£€æŸ¥é“¾å¼ find è°ƒç”¨"""
        code_lower = code.lower()
        
        # æ£€æµ‹ .find(...).find_all(...) æ¨¡å¼
        if ".find('tbody').find_all(" in code_lower or '.find("tbody").find_all(' in code_lower:
            self.issues.append(CodeIssue(
                code="ERR_002",
                severity=IssueSeverity.ERROR,
                message="æ£€æµ‹åˆ° find('tbody').find_all() é“¾å¼è°ƒç”¨ï¼Œå¯èƒ½å¯¼è‡´ç©ºæŒ‡é’ˆé”™è¯¯",
                suggestion="æ”¹ç”¨ soup.select('table tbody tr') æˆ–å¯¹ find ç»“æœåš None æ£€æŸ¥"
            ))
            return
        
        # æ›´é€šç”¨çš„æ£€æµ‹
        if "beautifulsoup" in code_lower or "from bs4 import" in code_lower:
            if ".find(" in code_lower and ").find_all(" in code_lower:
                self.issues.append(CodeIssue(
                    code="ERR_002",
                    severity=IssueSeverity.WARNING,
                    message="æ£€æµ‹åˆ° find().find_all() é“¾å¼è°ƒç”¨ï¼Œå­˜åœ¨ç©ºæŒ‡é’ˆé£é™©",
                    suggestion="ä¼˜å…ˆä½¿ç”¨ CSS é€‰æ‹©å™¨ soup.select()ï¼Œæˆ–å¯¹æ¯å±‚ find ç»“æœåš None æ£€æŸ¥"
                ))
    
    def _check_output_field_names(self, code: str) -> None:
        """æ£€æŸ¥è¾“å‡ºå­—æ®µå"""
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº† title è€Œä¸æ˜¯ name
        uses_title_key = '"title":' in code or "'title':" in code
        uses_name_key = '"name":' in code or "'name':" in code
        
        if uses_title_key and not uses_name_key:
            self.issues.append(CodeIssue(
                code="ERR_006",
                # å…¼å®¹ç­–ç•¥ï¼šå‰ç«¯/åç«¯å¯æŠŠ title è§†ä¸ºæŠ¥å‘Šåï¼ˆnameï¼‰çš„åˆ«åï¼Œä¸å¿…å¼ºåˆ¶è§¦å‘ä¿®å¤
                severity=IssueSeverity.WARNING,
                message="è¾“å‡ºå­—æ®µä½¿ç”¨äº† 'title' è€Œä¸æ˜¯ 'name'ï¼ˆå…¼å®¹ï¼štitle å°†è¢«è§†ä¸º nameï¼‰",
                suggestion="å»ºè®®å°† 'title' æ”¹ä¸º 'name'ï¼ˆå­—æ®µåæ¨è: name/date/downloadUrl/fileTypeï¼‰"
            ))
        
        # æ£€æŸ¥ downloadUrl å­—æ®µå
        uses_url_key = '"url":' in code or "'url':" in code
        uses_download_url_key = '"downloadUrl":' in code or "'downloadUrl':" in code
        
        if uses_url_key and not uses_download_url_key:
            self.issues.append(CodeIssue(
                code="ERR_006",
                severity=IssueSeverity.WARNING,
                message="è¾“å‡ºå­—æ®µä½¿ç”¨äº† 'url' è€Œä¸æ˜¯ 'downloadUrl'",
                suggestion="å°† 'url' æ”¹ä¸º 'downloadUrl'"
            ))
    
    def _check_spa_requests(self, code: str) -> None:
        """
        æ£€æŸ¥ SPA é¡µé¢ä½¿ç”¨ requests çš„é—®é¢˜ï¼ˆä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰ˆæœ¬ï¼‰
        
        æ”¹è¿›ï¼šç»“åˆ page_structure ä¸­çš„ spaHints åˆ¤æ–­é¡µé¢æ˜¯å¦çœŸçš„æ˜¯ SPA
        - å¦‚æœ spaHints æ˜ç¡®è¡¨ç¤ºæ˜¯ SPAï¼Œä¸”ä»£ç ç”¨ requests æŠ“ HTMLï¼Œåˆ™æŠ¥é”™
        - å¦‚æœæ²¡æœ‰ spaHintsï¼Œä»…é ä»£ç ä¸­çš„ /#/ æ¨¡å¼åˆ¤æ–­
        """
        code_lower = code.lower()
        
        # æ£€æµ‹æ˜¯å¦ç”¨ requests æŠ“å–
        if "requests.get(" not in code_lower:
            return
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯ SPA é¡µé¢
        is_spa = False
        spa_evidence = []
        
        # æ–¹å¼1ï¼šä» page_structure ä¸­è·å– SPA çº¿ç´¢
        if self.page_structure:
            spa_hints = self.page_structure.get('spaHints', {})
            if spa_hints.get('hasHashRoute'):
                is_spa = True
                spa_evidence.append("URL åŒ…å« /#/ è·¯ç”±")
            if spa_hints.get('hasAppRoot'):
                is_spa = True
                spa_evidence.append("é¡µé¢æœ‰ #app æ ¹å…ƒç´ ")
        
        # æ–¹å¼2ï¼šä»ä»£ç ä¸­æ£€æµ‹ï¼ˆé™çº§ï¼‰
        if not is_spa:
            if "/#/" in code:
                is_spa = True
                spa_evidence.append("ä»£ç ä¸­åŒ…å« /#/ URL")
        
        # å¦‚æœæ˜¯ SPA ä¸”ç”¨ requests æŠ“ HTMLï¼ˆè€Œä¸æ˜¯ APIï¼‰
        if is_spa and "playwright" not in code_lower:
            # æ£€æŸ¥æ˜¯å¦æ˜¯è°ƒç”¨ APIï¼ˆ.json() è¯´æ˜æ˜¯è°ƒç”¨ APIï¼Œä¸æ˜¯æŠ“ HTMLï¼‰
            if ".json()" in code_lower:
                return  # è°ƒç”¨ API æ˜¯æ­£ç¡®çš„
            
            self.issues.append(CodeIssue(
                code="ERR_005",
                severity=IssueSeverity.ERROR,
                message=f"æ£€æµ‹åˆ°ç”¨ requests æŠ“å– SPA é¡µé¢ ({', '.join(spa_evidence)})",
                suggestion="SPA é¡µé¢éœ€è¦ç”¨ Playwright æ¸²æŸ“åæå–ï¼Œæˆ–ç›´æ¥è°ƒç”¨ API æ¥å£è·å– JSON æ•°æ®"
            ))
    
    def _check_date_from_title(self, code: str) -> None:
        """æ£€æŸ¥ä»æ ‡é¢˜çŒœæµ‹æ—¥æœŸçš„é—®é¢˜"""
        patterns = [
            r'å¹´åº¦.*?report.*?(\d{4})',
            r"re\.search\(['\"].*å¹´.*['\"].*title",
            r"title.*å¹´.*date",
            r'f"{year}.*-12-31"',
            r"12-31.*date",
        ]
        
        for pattern in patterns:
            if re.search(pattern, code, re.IGNORECASE | re.DOTALL):
                self.issues.append(CodeIssue(
                    code="ERR_008",
                    severity=IssueSeverity.ERROR,
                    message="æ£€æµ‹åˆ°ä»æ ‡é¢˜æå–å¹´ä»½ä½œä¸ºæ—¥æœŸçš„æ¨¡å¼",
                    suggestion="ç»å¯¹ç¦æ­¢ä»æ ‡é¢˜çŒœæµ‹æ—¥æœŸï¼Œåº”ä» API æ—¥æœŸå­—æ®µæˆ– HTML æ—¥æœŸå…ƒç´ è·å–"
                ))
                return
    
    def _check_keeps_undated_records(self, code: str) -> None:
        """æ£€æŸ¥æ˜¯å¦ä¿ç•™äº†æ— æ—¥æœŸè®°å½•"""
        code_lower = code.lower()
        
        suspicious_patterns = [
            "elif not date_str",
            "if not date_str",
            "æ— æ—¥æœŸ" in code and "append(" in code_lower,
        ]
        
        pattern_count = sum(1 for p in suspicious_patterns if (p if isinstance(p, bool) else p in code_lower))
        
        # åŒæ—¶å‡ºç°å¤šä¸ªå¯ç–‘æ¨¡å¼æ‰æŠ¥å‘Š
        if pattern_count >= 2 or ("æ— æ—¥æœŸ" in code and "ä¿ç•™" in code):
            self.issues.append(CodeIssue(
                code="ERR_007",
                severity=IssueSeverity.WARNING,
                message="æ£€æµ‹åˆ°å¯èƒ½ä¿ç•™æ— æ—¥æœŸè®°å½•çš„é€»è¾‘",
                suggestion="å½“ç”¨æˆ·æŒ‡å®šæ—¥æœŸèŒƒå›´æ—¶ï¼Œæ— æ—¥æœŸè®°å½•åº”è¯¥ä¸¢å¼ƒè€Œä¸æ˜¯ä¿ç•™"
            ))
    
    def _check_single_page_dates(self, code: str) -> None:
        """æ£€æŸ¥æ˜¯å¦åªå¤„ç†ç¬¬ä¸€é¡µæ—¥æœŸ"""
        code_lower = code.lower()
        
        # æ£€æµ‹æ¨¡å¼ï¼šæœ‰åˆ†é¡µå¾ªç¯ï¼Œä½†æ—¥æœŸæå–åœ¨å¾ªç¯å¤–
        has_page_loop = "for page" in code_lower or "while" in code_lower
        has_date_extraction = "extract_date" in code_lower or "get_date" in code_lower
        
        if has_page_loop and has_date_extraction:
            # ç®€å•å¯å‘ï¼šå¦‚æœæ—¥æœŸæå–å‡½æ•°è°ƒç”¨ä¸åœ¨å¾ªç¯å†…
            lines = code.split('\n')
            in_loop = False
            date_in_loop = False
            
            for line in lines:
                if 'for ' in line.lower() and 'page' in line.lower():
                    in_loop = True
                if in_loop and ('extract_date' in line.lower() or 'get_date' in line.lower()):
                    date_in_loop = True
                    break
            
            if has_date_extraction and not date_in_loop:
                self.issues.append(CodeIssue(
                    code="ERR_003",
                    severity=IssueSeverity.WARNING,
                    message="æ—¥æœŸæå–å‡½æ•°å¯èƒ½åœ¨åˆ†é¡µå¾ªç¯å¤–è°ƒç”¨ï¼Œå¯èƒ½å¯¼è‡´åªæœ‰ç¬¬ä¸€é¡µæœ‰æ—¥æœŸ",
                    suggestion="ç¡®ä¿æ¯ä¸€é¡µéƒ½æå–æ—¥æœŸï¼Œåœ¨åŒä¸€ä¸ªå¾ªç¯ä¸­å¤„ç†æ•°æ®å’Œæ—¥æœŸ"
                ))
    
    def _check_missing_date_extraction(self, code: str) -> None:
        """
        æ£€æŸ¥é™æ€ HTML è§£æä¸­æ˜¯å¦é—æ¼æ—¥æœŸæå–ï¼ˆä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰ˆæœ¬ï¼‰
        
        æ”¹è¿›ï¼šç»“åˆ page_structure åˆ¤æ–­é¡µé¢æ˜¯å¦çœŸçš„æœ‰æ—¥æœŸå¯æå–
        - å¦‚æœ page_structure æ˜¾ç¤ºè¡¨æ ¼æ²¡æœ‰æ—¥æœŸåˆ—ï¼Œåˆ™ä¸æŠ¥é”™
        - å¦‚æœ page_structure æ˜¾ç¤ºæœ‰æ—¥æœŸåˆ—ä½†ä»£ç æ²¡æå–ï¼Œåˆ™æŠ¥é”™å¹¶æç¤ºæ—¥æœŸåˆ—ä½ç½®
        """
        code_lower = code.lower()
        
        # æ£€æµ‹æ˜¯å¦æ˜¯ BeautifulSoup è§£æé™æ€ HTML çš„ä»£ç 
        uses_bs4 = "beautifulsoup" in code_lower or "from bs4" in code_lower
        parses_table = "table" in code_lower and ("tr" in code_lower or "row" in code_lower)
        
        if not (uses_bs4 and parses_table):
            return  # ä¸æ˜¯é™æ€ HTML è§£æï¼Œè·³è¿‡
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æ—¥æœŸæå–ç›¸å…³çš„ä»£ç 
        has_date_extraction = any([
            "_pygen_smart_find_date" in code,
            "_smart_find_date" in code,
            "normalize_date" in code_lower,
            "extract_date" in code_lower,
            "find_date" in code_lower,
            # æ£€æŸ¥æ˜¯å¦æœ‰æ—¥æœŸå­—æ®µçš„èµ‹å€¼
            re.search(r'"date"\s*:', code),
            re.search(r"'date'\s*:", code),
            # æ£€æŸ¥æ˜¯å¦æœ‰æ—¥æœŸæ­£åˆ™
            re.search(r'\\d{4}.*[-/].*\\d{1,2}', code),
        ])
        
        # æ£€æŸ¥è¾“å‡ºå­—å…¸ä¸­æ˜¯å¦åŒ…å« date å­—æ®µ
        has_date_in_output = re.search(r'["\']date["\']\s*:', code) is not None
        
        # å¦‚æœå·²ç»æœ‰æ—¥æœŸæå–é€»è¾‘ï¼Œè·³è¿‡
        if has_date_extraction or has_date_in_output:
            return
        
        # ç»“åˆ page_structure åˆ¤æ–­æ˜¯å¦éœ€è¦æŠ¥é”™
        if self.page_structure:
            tables = self.page_structure.get('tables', [])
            date_elements = self.page_structure.get('dateElements', [])
            
            # æ£€æŸ¥è¡¨æ ¼æ˜¯å¦æœ‰æ—¥æœŸåˆ—
            has_date_column = False
            date_col_info = ""
            if tables:
                table = tables[0]
                date_hints = table.get('dateColumnHints', [])
                if date_hints:
                    has_date_column = True
                    date_col_info = f"ï¼ˆæ—¥æœŸåœ¨ç¬¬{date_hints[0].get('columnIndex')}åˆ—ã€Œ{date_hints[0].get('headerText', '?')}ã€ï¼‰"
            
            # æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰æ—¥æœŸå…ƒç´ 
            if date_elements:
                has_date_column = True
                if not date_col_info:
                    date_col_info = f"ï¼ˆé¡µé¢æœ‰ {len(date_elements)} ä¸ªæ—¥æœŸå…ƒç´ ï¼Œå¦‚ {date_elements[0].get('selector')}ï¼‰"
            
            if has_date_column:
                # é¡µé¢æœ‰æ—¥æœŸä½†ä»£ç æ²¡æå–ï¼ŒæŠ¥é”™
                self.issues.append(CodeIssue(
                    code="ERR_009",
                    severity=IssueSeverity.ERROR,
                    message=f"é™æ€ HTML è¡¨æ ¼è§£ææœªåŒ…å«æ—¥æœŸæå–é€»è¾‘{date_col_info}",
                    suggestion="åœ¨éå†è¡¨æ ¼è¡Œæ—¶ä½¿ç”¨ _pygen_smart_find_date_in_row_bs4(tds) æå–æ—¥æœŸ"
                ))
            else:
                # é¡µé¢æ²¡æœ‰æ£€æµ‹åˆ°æ—¥æœŸåˆ—ï¼Œåªç»™æç¤º
                self.issues.append(CodeIssue(
                    code="ERR_009",
                    severity=IssueSeverity.INFO,
                    message="é™æ€ HTML è¡¨æ ¼è§£ææœªåŒ…å«æ—¥æœŸæå–é€»è¾‘ï¼Œä½†é¡µé¢ç»“æ„ä¸­æœªæ£€æµ‹åˆ°æ—¥æœŸåˆ—",
                    suggestion="å¦‚æœè¡¨æ ¼ç¡®å®æ²¡æœ‰æ—¥æœŸåˆ—ï¼Œå¯å¿½ç•¥æ­¤æç¤ºï¼›å¦åˆ™è¯·æ£€æŸ¥æ—¥æœŸæå–é€»è¾‘"
                ))
        else:
            # æ²¡æœ‰ page_structureï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘ä½†é™çº§ä¸ºè­¦å‘Š
            self.issues.append(CodeIssue(
                code="ERR_009",
                severity=IssueSeverity.WARNING,
                message="é™æ€ HTML è¡¨æ ¼è§£ææœªåŒ…å«æ—¥æœŸæå–é€»è¾‘ï¼Œå¯èƒ½å¯¼è‡´æ‰€æœ‰è®°å½•æ—¥æœŸä¸ºç©º",
                suggestion="åœ¨éå†è¡¨æ ¼è¡Œæ—¶ä½¿ç”¨ _pygen_smart_find_date_in_row_bs4(tds) æå–æ—¥æœŸ"
            ))
    
    def _check_unicode_print_chars(self, code: str) -> None:
        """æ£€æŸ¥ print è¯­å¥ä¸­æ˜¯å¦åŒ…å«å¯èƒ½å¯¼è‡´ç¼–ç é”™è¯¯çš„ Unicode å­—ç¬¦"""
        # å¸¸è§çš„é—®é¢˜å­—ç¬¦
        problem_chars = ['âœ“', 'âœ—', 'âœ”', 'âœ˜', 'â†’', 'â†', 'â†‘', 'â†“', 'â—', 'â—‹', 'â– ', 'â–¡', 'â˜…', 'â˜†']
        
        # åªæ£€æŸ¥ print è¯­å¥
        print_pattern = re.compile(r'print\s*\([^)]*\)', re.MULTILINE | re.DOTALL)
        print_statements = print_pattern.findall(code)
        
        for stmt in print_statements:
            for char in problem_chars:
                if char in stmt:
                    self.issues.append(CodeIssue(
                        code="ERR_010",
                        severity=IssueSeverity.WARNING,
                        message=f"print è¯­å¥åŒ…å« Unicode å­—ç¬¦ '{char}'ï¼Œå¯èƒ½åœ¨ Windows GBK æ§åˆ¶å°å¯¼è‡´ç¼–ç é”™è¯¯",
                        suggestion="ä½¿ç”¨ ASCII å­—ç¬¦æ›¿ä»£ï¼Œå¦‚ [OK]ã€[FAIL]ã€-> ç­‰"
                    ))
                    return  # åªæŠ¥å‘Šä¸€æ¬¡


# ============================================================================
# è¾“å‡ºéªŒè¯å™¨
# ============================================================================

class OutputValidator:
    """
    è¾“å‡ºéªŒè¯å™¨ - éªŒè¯çˆ¬è™«è¾“å‡ºçš„ JSON æ•°æ®
    
    éªŒè¯é¡¹ï¼š
    1. ç»“æ„å®Œæ•´æ€§ï¼ˆPydantic æ¨¡å‹éªŒè¯ï¼‰
    2. æ•°æ®è´¨é‡æ£€æŸ¥ï¼ˆæ—¥æœŸå¡«å……ç‡ã€URL æœ‰æ•ˆæ€§ç­‰ï¼‰
    """
    
    def __init__(self, min_date_fill_rate: float = 0.3):
        """
        åˆå§‹åŒ–éªŒè¯å™¨
        
        Args:
            min_date_fill_rate: æœ€å°æ—¥æœŸå¡«å……ç‡è¦æ±‚ (0-1)
        """
        self.min_date_fill_rate = min_date_fill_rate
        self.errors: List[str] = []
        self.warnings: List[str] = []
    
    def validate_output(self, data: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """
        éªŒè¯è¾“å‡ºæ•°æ®
        
        Args:
            data: çˆ¬è™«è¾“å‡ºçš„ JSON æ•°æ®
            
        Returns:
            (æ˜¯å¦é€šè¿‡éªŒè¯, é”™è¯¯åˆ—è¡¨)
        """
        self.errors = []
        self.warnings = []
        
        # 1. Pydantic ç»“æ„éªŒè¯
        try:
            output = CrawlOutput(**data)
        except ValidationError as e:
            for error in e.errors():
                field = ".".join(str(x) for x in error['loc'])
                self.errors.append(f"å­—æ®µ {field}: {error['msg']}")
            return False, self.errors
        
        # 2. æ•°æ®è´¨é‡æ£€æŸ¥
        reports = data.get('reports', [])
        if not reports:
            self.errors.append("reports åˆ—è¡¨ä¸ºç©º")
            return False, self.errors
        
        # æ—¥æœŸå¡«å……ç‡
        date_count = sum(1 for r in reports if r.get('date'))
        date_fill_rate = date_count / len(reports) if reports else 0
        
        if date_fill_rate < self.min_date_fill_rate:
            self.warnings.append(
                f"æ—¥æœŸå¡«å……ç‡è¾ƒä½: {date_fill_rate:.1%} (æœŸæœ› >= {self.min_date_fill_rate:.1%})"
            )
        
        # æ£€æŸ¥ total ä¸å®é™…æ•°é‡æ˜¯å¦åŒ¹é…
        if data.get('total', 0) != len(reports):
            self.warnings.append(
                f"total ({data.get('total')}) ä¸ reports æ•°é‡ ({len(reports)}) ä¸åŒ¹é…"
            )
        
        # URL æ ¼å¼æ£€æŸ¥
        invalid_urls = []
        for i, r in enumerate(reports):
            url = r.get('downloadUrl', '')
            if url and not url.startswith(('http://', 'https://', '//')):
                invalid_urls.append(f"#{i+1}: {url[:50]}")
        
        if invalid_urls:
            self.warnings.append(f"å‘ç° {len(invalid_urls)} ä¸ªæ— æ•ˆ URL: {invalid_urls[:3]}")
        
        # åªæœ‰é”™è¯¯æ‰è¿”å›å¤±è´¥
        return len(self.errors) == 0, self.errors + self.warnings
    
    def get_quality_report(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š
        
        Args:
            data: çˆ¬è™«è¾“å‡ºçš„ JSON æ•°æ®
            
        Returns:
            è´¨é‡æŠ¥å‘Šå­—å…¸
        """
        reports = data.get('reports', [])
        
        if not reports:
            return {
                "total_records": 0,
                "date_fill_rate": 0,
                "url_valid_rate": 0,
                "avg_name_length": 0,
                "status": "empty"
            }
        
        # ç»Ÿè®¡å„é¡¹æŒ‡æ ‡
        date_count = sum(1 for r in reports if r.get('date'))
        valid_url_count = sum(
            1 for r in reports 
            if r.get('downloadUrl', '').startswith(('http://', 'https://'))
        )
        name_lengths = [len(r.get('name', '')) for r in reports]
        
        return {
            "total_records": len(reports),
            "date_fill_rate": date_count / len(reports),
            "url_valid_rate": valid_url_count / len(reports),
            "avg_name_length": sum(name_lengths) / len(name_lengths),
            "empty_date_count": len(reports) - date_count,
            "invalid_url_count": len(reports) - valid_url_count,
            "status": "ok" if date_count > 0 and valid_url_count == len(reports) else "warning"
        }


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

def validate_code(code: str, page_structure: Optional[Dict[str, Any]] = None) -> Tuple[bool, List[CodeIssue]]:
    """
    éªŒè¯ä»£ç çš„ä¾¿æ·å‡½æ•°ï¼ˆæ”¯æŒä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼‰
    
    Args:
        code: Python ä»£ç å­—ç¬¦ä¸²
        page_structure: é¡µé¢ç»“æ„ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œæ¥è‡ª browser.analyze_page_structure()ï¼‰
        
    Returns:
        (æ˜¯å¦é€šè¿‡, é—®é¢˜åˆ—è¡¨)
    """
    validator = StaticCodeValidator()
    issues = validator.validate(code, page_structure=page_structure)
    return not validator.has_errors(), issues


def validate_output(data: Dict[str, Any]) -> Tuple[bool, List[str]]:
    """
    éªŒè¯è¾“å‡ºçš„ä¾¿æ·å‡½æ•°
    
    Args:
        data: JSON æ•°æ®
        
    Returns:
        (æ˜¯å¦é€šè¿‡, é”™è¯¯åˆ—è¡¨)
    """
    validator = OutputValidator()
    return validator.validate_output(data)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç éªŒè¯å™¨
    test_code = """
    def fetch_data():
        soup = BeautifulSoup(html, 'html.parser')
        table = soup.find('table')
        rows = table.find('tbody').find_all('tr')  # è¿™ä¼šè¢«æ£€æµ‹åˆ°
        
        for row in rows:
            tds = row.find_all('td')
            date = tds[4].select_one('span').get_text()  # è¿™ä¹Ÿä¼šè¢«æ£€æµ‹åˆ°
            reports.append({
                "title": name,  # åº”è¯¥æ˜¯ name
                "date": date,
                "url": url  # åº”è¯¥æ˜¯ downloadUrl
            })
    """
    
    validator = StaticCodeValidator()
    issues = validator.validate(test_code)
    print(validator.get_summary())
    print("\n" + "=" * 60 + "\n")
    print("ä¿®å¤æç¤º:")
    print(validator.get_repair_prompt())

