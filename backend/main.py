#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PyGen - æ™ºèƒ½çˆ¬è™«è„šæœ¬ç”Ÿæˆå™¨ï¼ˆå¢å¼ºç‰ˆï¼‰

ç»™å®šåˆ—è¡¨é¡µURLï¼Œè‡ªåŠ¨åˆ†æé¡µé¢ç»“æ„å¹¶ç”Ÿæˆç‹¬ç«‹å¯è¿è¡Œçš„Pythonçˆ¬è™«è„šæœ¬ã€‚

å¢å¼ºåŠŸèƒ½ï¼š
- ç©ºæ•°æ®æ£€æµ‹ï¼šè¯†åˆ«éœ€è¦äº¤äº’æ‰èƒ½åŠ è½½æ•°æ®çš„SPAé¡µé¢
- äº¤äº’å¼APIæ•è·ï¼šè‡ªåŠ¨ç‚¹å‡»èœå•æ¢æµ‹å®Œæ•´çš„APIå‚æ•°
- åˆ†ç±»å‚æ•°åˆ†æï¼šè¯†åˆ«å¿…éœ€çš„åˆ†ç±»/ç­›é€‰å‚æ•°

ä½¿ç”¨æ–¹æ³•ï¼š
    python main.py

æˆ–ç›´æ¥æŒ‡å®šURLï¼š
    python main.py https://example.com/list
"""
import asyncio
import sys
import os
import time
import json
import argparse
import re
import fnmatch
from datetime import datetime
from pathlib import Path

# Richåº“ç”¨äºç¾åŒ–è¾“å‡º
try:
    from rich.console import Console
    from rich.panel import Panel
    from rich.prompt import Prompt, Confirm
    from rich.progress import Progress, SpinnerColumn, TextColumn
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False
    print("æç¤ºï¼šå®‰è£… rich åº“å¯è·å¾—æ›´å¥½çš„æ˜¾ç¤ºæ•ˆæœ: pip install rich")

from config import Config
from chrome_launcher import ChromeLauncher
from browser_controller import BrowserController
from llm_agent import LLMAgent
from date_extractor import get_injectable_code as get_date_extractor_code

def _match_path(pattern: str, path: str) -> bool:
    """
    è·¯å¾„åŒ¹é…è§„åˆ™ï¼š
    - å‰ç¼€å­æ ‘ï¼š`xxx/**` åŒ¹é… xxx åŠå…¶å­è·¯å¾„
    - æ­£åˆ™ï¼š`re:<pattern>`
    - å…¶ä»–ï¼šfnmatchï¼ˆæ”¯æŒ * ? []ï¼‰
    """
    if not pattern:
        return False
    pattern = pattern.strip()
    if pattern.startswith("re:"):
        try:
            return re.search(pattern[3:], path) is not None
        except re.error:
            return False
    if pattern.endswith("/**"):
        prefix = pattern[:-3].rstrip("/")
        return path == prefix or path.startswith(prefix + "/")
    return fnmatch.fnmatchcase(path, pattern)

def _parse_menu_select(requirements: str) -> dict:
    """
    ä»â€œé¢å¤–éœ€æ±‚â€ä¸­è§£æ menu_select è§„åˆ™ï¼ˆæ¨è JSON/YAML-likeï¼‰ã€‚
    æ”¯æŒï¼š
      - JSONï¼š{"menu_select":{"include":[...],"exclude":[...]}}
      - ç®€åŒ–æ–‡æœ¬ï¼š
          include: a/**,b/**
          exclude: c/**,d/**
    """
    result = {"include": [], "exclude": []}
    if not requirements:
        return result
    txt = requirements.strip()
    # 1) JSON
    try:
        obj = json.loads(txt)
        ms = obj.get("menu_select", {}) if isinstance(obj, dict) else {}
        inc = ms.get("include", []) if isinstance(ms, dict) else []
        exc = ms.get("exclude", []) if isinstance(ms, dict) else []
        if isinstance(inc, list):
            result["include"] = [str(x) for x in inc]
        if isinstance(exc, list):
            result["exclude"] = [str(x) for x in exc]
        return result
    except Exception:
        pass
    # 2) ç®€åŒ–æ–‡æœ¬
    for line in txt.splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        if ":" not in line:
            continue
        k, v = line.split(":", 1)
        k = k.strip().lower()
        items = [x.strip() for x in re.split(r"[,\s]+", v.strip()) if x.strip()]
        if k == "include":
            result["include"].extend(items)
        elif k == "exclude":
            result["exclude"].extend(items)
    return result

def _filter_leaf_paths(leaf_paths: list, include: list, exclude: list) -> list:
    """æŒ‰ include/exclude è§„åˆ™ç­›é€‰å¶å­è·¯å¾„ã€‚include ä¸ºç©ºè¡¨ç¤ºå…¨é€‰ã€‚"""
    selected = []
    for p in leaf_paths:
        if include:
            ok = any(_match_path(rule, p) for rule in include)
            if not ok:
                continue
        if exclude and any(_match_path(rule, p) for rule in exclude):
            continue
        selected.append(p)
    return selected

def _remove_late_hardcoded_dates(script: str) -> str:
    """
    åˆ é™¤/æ³¨é‡Šæ‰è„šæœ¬ä¸­åç»­å†æ¬¡èµ‹å€¼ START_DATE/END_DATE çš„è¡Œï¼Œé¿å…è¦†ç›–æ³¨å…¥å—ã€‚
    è§„åˆ™ï¼šä¿ç•™æ³¨å…¥å—é‡Œçš„ START_DATE, END_DATEï¼›å…¶åé‡åˆ°è£¸èµ‹å€¼è¡Œå°±æ³¨é‡Šæ‰ã€‚
    """
    lines = script.splitlines()
    out = []
    saw_injected = False
    for line in lines:
        if line.startswith("# === PyGen æ³¨å…¥ï¼šæ—¥æœŸèŒƒå›´"):
            saw_injected = True
            out.append(line)
            continue
        if saw_injected and re.match(r'^\s*START_DATE\s*=\s*["\']', line):
            out.append("# " + line + "  # (disabled by PyGen: injected dates take precedence)")
            continue
        if saw_injected and re.match(r'^\s*END_DATE\s*=\s*["\']', line):
            out.append("# " + line + "  # (disabled by PyGen: injected dates take precedence)")
            continue
        out.append(line)
    return "\n".join(out) + ("\n" if script.endswith("\n") else "")

def _inject_dates_and_categories(script_code: str, start_date: str, end_date: str, verified_mapping: dict) -> str:
    """
    ç”Ÿæˆååå¤„ç†ï¼š
    - å¼ºåˆ¶æ³¨å…¥ START_DATE / END_DATEï¼ˆé»˜è®¤=æœ¬æ¬¡è¾“å…¥ï¼Œå…è®¸å‘½ä»¤è¡Œ/ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
    - å¼ºåˆ¶è¦†ç›– CATEGORIESï¼ˆåªä½¿ç”¨çœŸå®æŠ“åŒ…å¾—åˆ°çš„æ˜ å°„ï¼Œé¿å…æ¨¡å‹çŒœï¼‰
    """
    # 1) æ—¥æœŸï¼šæ’å…¥ä¸€ä¸ªâ€œæƒå¨æ—¥æœŸå—â€ï¼Œå¹¶å°½é‡æ›¿æ¢è„šæœ¬å†…çš„ç¡¬ç¼–ç 
    date_block = f'''
# === PyGen æ³¨å…¥ï¼šæ—¥æœŸèŒƒå›´ï¼ˆæƒå¨æ¥æºï¼šæœ¬æ¬¡è¾“å…¥ï¼‰ ===
# å…è®¸é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼šPYGEN_START_DATE / PYGEN_END_DATE
# å…è®¸é€šè¿‡å‘½ä»¤è¡Œè¦†ç›–ï¼š--start-date / --end-date
import argparse as _argparse
import os as _os

def _pygen_resolve_dates():
    parser = _argparse.ArgumentParser(add_help=False)
    parser.add_argument("--start-date", dest="start_date")
    parser.add_argument("--end-date", dest="end_date")
    args, _ = parser.parse_known_args()
    sd = args.start_date or _os.getenv("PYGEN_START_DATE") or "{start_date}"
    ed = args.end_date or _os.getenv("PYGEN_END_DATE") or "{end_date}"
    return sd, ed

START_DATE, END_DATE = _pygen_resolve_dates()
# === PyGen æ³¨å…¥ç»“æŸ ===
'''

    # è‹¥è„šæœ¬é‡Œå·²ç»æœ‰ START_DATE/END_DATEï¼Œç›´æ¥åœ¨æœ€å‰é¢æ³¨å…¥å¹¶è¦†ç›–å³å¯ï¼ˆåç»­å¼•ç”¨å°†æ‹¿åˆ°æ³¨å…¥å€¼ï¼‰
    # ä¸ºäº†é¿å…é‡å¤å®šä¹‰å¯¼è‡´è¯¯è¯»ï¼Œä¹Ÿåšä¸€æ¬¡ç®€å•æ›¿æ¢æŠŠç¡¬ç¼–ç æ”¹æˆå ä½ï¼ˆä¸è¿½æ±‚å®Œç¾ï¼Œæ³¨å…¥è¦†ç›–å·²è¶³å¤Ÿï¼‰
    script = script_code
    script = script.replace('START_DATE = "2026-01-01"', f'START_DATE = "{start_date}"')
    script = script.replace('END_DATE = "2026-12-31"', f'END_DATE = "{end_date}"')

    # åœ¨ç¬¬ä¸€ä¸ª import ä¹‹åæ’å…¥ date_blockï¼ˆä¿æŒ shebang/encoding åœ¨æœ€é¡¶éƒ¨ï¼‰
    lines = script.splitlines()
    insert_at = 0
    for i, line in enumerate(lines[:60]):
        if line.startswith("import ") or line.startswith("from "):
            insert_at = i
            break
    else:
        insert_at = min(2, len(lines))
    lines.insert(insert_at, date_block.strip("\n"))
    script = "\n".join(lines) + "\n"

    # 2) åˆ†ç±»æ˜ å°„ï¼ˆä¸¤ç§å½¢æ€ï¼‰ï¼š
    # - menu_to_filtersï¼šåŒä¸€ä¸ªåˆ—è¡¨æ¥å£ + ä¸åŒ filters å‚æ•°ï¼ˆSPA/æ¥å£å‹ï¼‰
    # - menu_to_urlsï¼šä¸åŒæ¿å—å¯¹åº”ä¸åŒåˆ—è¡¨é¡µ URLï¼ˆæœåŠ¡ç«¯æ¸²æŸ“/è·³è½¬å‹ï¼‰
    menu_to_filters = (verified_mapping or {}).get("menu_to_filters") if isinstance(verified_mapping, dict) else None
    menu_to_urls = (verified_mapping or {}).get("menu_to_urls") if isinstance(verified_mapping, dict) else None

    converted_categories = None
    categories_comment = None

    if menu_to_filters:
        converted_categories = {}
        for cat_name, cat_params in menu_to_filters.items():
            filter_obj = {"launchedstatus": "å¯ç”¨"}
            filter_obj.update(cat_params)
            orderby = {"rankdate": "desc"}
            converted_categories[cat_name] = {"filters": filter_obj, "orderby": orderby}
        categories_comment = "å¯ä¿¡åˆ†ç±»æ˜ å°„ï¼ˆæ¥æºï¼šçœŸå®äº¤äº’æŠ“åŒ… filtersï¼‰"
    elif menu_to_urls:
        # URL å‹åˆ†ç±»æ˜ å°„ï¼šè®©è„šæœ¬éå† URL æŠ“å–ï¼ˆä¸ä¾èµ– filters APIï¼‰
        converted_categories = {}
        for cat_name, url in menu_to_urls.items():
            if not url:
                continue
            converted_categories[cat_name] = {"url": url}
        categories_comment = "å¯ä¿¡åˆ†ç±»æ˜ å°„ï¼ˆæ¥æºï¼šç›®å½•æ ‘è·³è½¬ URLï¼‰"

    if converted_categories:
        categories_block = f"\n# === PyGen æ³¨å…¥ï¼š{categories_comment} ===\n"
        categories_block += "CATEGORIES = " + json.dumps(converted_categories, ensure_ascii=False, indent=2) + "\n"
        categories_block += "# === PyGen æ³¨å…¥ç»“æŸ ===\n"

        # é¢å¤–å…œåº•ï¼šURL å‹åˆ†ç±»æ˜ å°„æ—¶ï¼Œå¼ºåˆ¶éå† CATEGORIESï¼ˆé¿å… LLM å¿½ç•¥ CATEGORIES ä»åªçˆ¬å•é¡µï¼‰
        # æ€è·¯ï¼š
        # - æš‚æ—¶åŠ«æŒè„šæœ¬é‡Œçš„ save_results()ï¼šæ”¹ä¸ºâ€œåªç´¯ç§¯ä¸è½ç›˜â€
        # - æš‚æ—¶åŠ«æŒè„šæœ¬é‡Œçš„ main()ï¼šæ”¹ä¸ºéå† CATEGORIES.urlï¼Œæ¯ä¸ª URL éƒ½æ‰§è¡Œä¸€æ¬¡åŸ main()
        # - æœ€åç”¨åŸ save_results() ä¸€æ¬¡æ€§æŠŠåˆå¹¶ç»“æœå†™å…¥ä¸€ä¸ª JSON æ–‡ä»¶
        if menu_to_urls:
            categories_block += """
# === PyGen æ³¨å…¥ï¼šURL åˆ†ç±»éå†å…œåº•ï¼ˆåˆå¹¶è¾“å‡ºï¼‰===
try:
    _pygen__has_urls = isinstance(globals().get("CATEGORIES"), dict) and any(
        isinstance(v, dict) and v.get("url") for v in globals().get("CATEGORIES", {}).values()
    )
except Exception:
    _pygen__has_urls = False

if _pygen__has_urls:
    import os as _os2
    import json as _json2
    from datetime import datetime as _dt2

    _pygen__orig_main = globals().get("main")
    _pygen__accumulated = []

    def _pygen__get_output_dir():
        try:
            _default = _os2.path.abspath(_os2.path.join(_os2.path.dirname(__file__), "..", "output"))
        except Exception:
            _default = "."
        out_dir = globals().get("OUTPUT_DIR") or _default
        if not isinstance(out_dir, str) or not out_dir.strip():
            out_dir = _default
        out_dir = out_dir.strip()
        if out_dir.lower().endswith(".json"):
            out_dir = _os2.path.dirname(out_dir) or _default
        try:
            _os2.makedirs(out_dir, exist_ok=True)
        except Exception:
            out_dir = _default or "."
        return out_dir

    def _pygen__list_json_files(out_dir):
        try:
            return {
                f for f in _os2.listdir(out_dir)
                if f.endswith(".json") and _os2.path.isfile(_os2.path.join(out_dir, f))
            }
        except Exception:
            return set()

    def _pygen__read_articles_from_json(filepath):
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                data = _json2.load(f)
            articles = data.get("articles") or data.get("news") or data.get("reports") or []
            if isinstance(articles, list):
                return articles
        except Exception:
            pass
        return []

    def _pygen_run_all_categories():
        global _pygen__accumulated
        try:
            out_dir = _pygen__get_output_dir()
            cats = globals().get("CATEGORIES", {})

            for _name, _cfg in (cats or {}).items():
                _url = _cfg.get("url") if isinstance(_cfg, dict) else None
                if not _url or not isinstance(_url, str):
                    continue

                before_files = _pygen__list_json_files(out_dir)

                try:
                    globals()["BASE_URL"] = _url if _url.endswith("/") else (_url + "/")
                except Exception:
                    pass

                try:
                    if callable(_pygen__orig_main):
                        _pygen__orig_main()
                except Exception as e:
                    print(f"[WARN] åˆ†ç±» {_name} æ‰§è¡Œå¤±è´¥: {e}")
                    continue

                after_files = _pygen__list_json_files(out_dir)
                new_files = after_files - before_files

                for fname in new_files:
                    fpath = _os2.path.join(out_dir, fname)
                    articles = _pygen__read_articles_from_json(fpath)
                    if articles:
                        # ç»™æ¯æ¡æ•°æ®æ·»åŠ  category å­—æ®µï¼Œè®°å½•æ¥æºæ¿å—
                        for art in articles:
                            if isinstance(art, dict) and "category" not in art:
                                art["category"] = _name
                        _pygen__accumulated.extend(articles)
                        print(f"[INFO] ä» {fname} è¯»å– {len(articles)} æ¡æ•°æ® (åˆ†ç±»: {_name})")

            ts = _dt2.now().strftime("%Y%m%d_%H%M%S")
            out_path = _os2.path.join(out_dir, f"pygen_multi_{ts}.json")
            with open(out_path, "w", encoding="utf-8") as f:
                _json2.dump({
                    "total": len(_pygen__accumulated),
                    "crawlTime": _dt2.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "dateRange": {
                        "start": globals().get("START_DATE", ""),
                        "end": globals().get("END_DATE", ""),
                    },
                    "articles": _pygen__accumulated,
                }, f, ensure_ascii=False, indent=2)
            print(f"[SUCCESS] å·²åˆå¹¶ä¿å­˜ {len(_pygen__accumulated)} æ¡æ•°æ®: {out_path}")

        except Exception as e:
            print(f"[WARN] å¤šåˆ†ç±»éå†å¤±è´¥: {e}")

    def main():  # type: ignore
        return _pygen_run_all_categories()

# === PyGen æ³¨å…¥ç»“æŸ ===
"""

        marker = 'if __name__ == "__main__":'
        idx = script.rfind(marker)
        if idx != -1:
            script = script[:idx] + categories_block + script[idx:]
        else:
            script += categories_block

    return script

def _inject_selected_categories_and_fix_dates(script_code: str, start_date: str, end_date: str, verified_mapping: dict) -> str:
    """ç»„åˆåå¤„ç†ï¼šæ³¨å…¥æ—¥æœŸ/åˆ†ç±»æ˜ å°„ + ç¦ç”¨åç»­ç¡¬ç¼–ç æ—¥æœŸè¦†ç›–ã€‚"""
    s = _inject_dates_and_categories(script_code, start_date, end_date, verified_mapping)
    s = _remove_late_hardcoded_dates(s)
    return s

# =============================================================================
# ä»¥ä¸‹å‡½æ•°å·²ç§»è‡³ post_processor.pyï¼Œä¿ç•™å­˜æ ¹ä»¥ä¿æŒå‘åå…¼å®¹
# =============================================================================

def _inject_http_resilience(script_code: str) -> str:
    """[å·²åºŸå¼ƒ] è¯·ä½¿ç”¨ post_processor.inject_http_resilience"""
    from post_processor import inject_http_resilience
    return inject_http_resilience(script_code)

def _inject_date_extraction_resilience(script_code: str) -> str:
    """[å·²åºŸå¼ƒ] è¯·ä½¿ç”¨ post_processor.inject_date_extraction_tools"""
    from post_processor import inject_date_extraction_tools
    return inject_date_extraction_tools(script_code)

def _fix_brittle_table_selectors(script_code: str) -> str:
    """[å·²åºŸå¼ƒ] è¯·ä½¿ç”¨ post_processor.fix_brittle_table_selectors"""
    from post_processor import fix_brittle_table_selectors
    return fix_brittle_table_selectors(script_code)

def _fix_hardcoded_date_extraction(script_code: str) -> str:
    """[å·²åºŸå¼ƒ] è¯¥å‡½æ•°å·²åˆ é™¤ï¼Œä¸ LLM æ™ºèƒ½ä¿®å¤å†²çª"""
    # ä¸å†æ‰§è¡Œä»»ä½•æ“ä½œï¼Œè¿”å›åŸä»£ç 
    return script_code



# åˆå§‹åŒ–æ§åˆ¶å°
if RICH_AVAILABLE:
    console = Console()
else:
    class FakeConsole:
        def print(self, *args, **kwargs):
            text = str(args[0]) if args else ""
            import re
            text = re.sub(r'\[.*?\]', '', text)
            print(text)
    console = FakeConsole()


def print_banner():
    """æ‰“å°æ¬¢è¿æ¨ªå¹…"""
    if RICH_AVAILABLE:
        banner = """
[bold cyan]â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                          â”‚
â”‚      ğŸ•·ï¸ PyGen - æ™ºèƒ½çˆ¬è™«è„šæœ¬ç”Ÿæˆå™¨ v2.0                  â”‚
â”‚                                                          â”‚
â”‚      ç»™å®šåˆ—è¡¨é¡µURLï¼Œè‡ªåŠ¨ç”ŸæˆPythonçˆ¬è™«è„šæœ¬               â”‚
â”‚      [å¢å¼ºç‰ˆ] æ”¯æŒSPAé¡µé¢åˆ†ç±»å‚æ•°è‡ªåŠ¨è¯†åˆ«               â”‚
â”‚                                                          â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[/bold cyan]
"""
        console.print(banner)
    else:
        print("=" * 60)
        print("  PyGen - æ™ºèƒ½çˆ¬è™«è„šæœ¬ç”Ÿæˆå™¨ v2.0")
        print("  ç»™å®šåˆ—è¡¨é¡µURLï¼Œè‡ªåŠ¨ç”ŸæˆPythonçˆ¬è™«è„šæœ¬")
        print("  [å¢å¼ºç‰ˆ] æ”¯æŒSPAé¡µé¢åˆ†ç±»å‚æ•°è‡ªåŠ¨è¯†åˆ«")
        print("=" * 60)


def get_user_input() -> dict:
    """è·å–ç”¨æˆ·è¾“å…¥"""
    console.print("\n[bold]è¯·è¾“å…¥ç›®æ ‡åˆ—è¡¨é¡µä¿¡æ¯ï¼š[/bold]\n")

    # URLè¾“å…¥
    if RICH_AVAILABLE:
        url = Prompt.ask("[cyan]ç›®æ ‡åˆ—è¡¨é¡µURL[/cyan]")
    else:
        url = input("ç›®æ ‡åˆ—è¡¨é¡µURL: ")

    if not url.startswith("http"):
        url = "https://" + url

    # çˆ¬å–æ—¶é—´èŒƒå›´
    console.print("\n[dim]è®¾ç½®çˆ¬å–çš„æ—¶é—´èŒƒå›´ï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰[/dim]")
    if RICH_AVAILABLE:
        start_date = Prompt.ask("[cyan]å¼€å§‹æ—¶é—´[/cyan]", default="2026-01-01")
        end_date = Prompt.ask("[cyan]ç»“æŸæ—¶é—´[/cyan]", default="2026-12-31")
    else:
        start_date = input("å¼€å§‹æ—¶é—´ [2026-01-01]: ") or "2026-01-01"
        end_date = input("ç»“æŸæ—¶é—´ [2026-12-31]: ") or "2026-12-31"

    # é¢å¤–éœ€æ±‚ï¼ˆå¯é€‰ï¼‰
    console.print("\n[dim]å¯é€‰ï¼šæè¿°ä½ æƒ³è¦çˆ¬å–çš„å…·ä½“å†…å®¹ï¼ˆç•™ç©ºåˆ™è‡ªåŠ¨åˆ†æï¼‰[/dim]")
    if RICH_AVAILABLE:
        requirements = Prompt.ask("[cyan]é¢å¤–éœ€æ±‚[/cyan]", default="")
    else:
        requirements = input("é¢å¤–éœ€æ±‚ï¼ˆå¯é€‰ï¼‰: ")

    # è¾“å‡ºæ–‡ä»¶å
    if RICH_AVAILABLE:
        output_name = Prompt.ask(
            "[cyan]è¾“å‡ºè„šæœ¬åç§°[/cyan]",
            default="crawler"
        )
    else:
        output_name = input("è¾“å‡ºè„šæœ¬åç§° [crawler]: ") or "crawler"

    if not output_name.endswith(".py"):
        output_name += ".py"

    return {
        "url": url,
        "start_date": start_date,
        "end_date": end_date,
        "requirements": requirements,
        "output_name": output_name,
    }


async def run_generation(
    url: str,
    requirements: str,
    output_name: str,
    config: Config,
    start_date: str = "",
    end_date: str = "",
    include_rules: list | None = None,
    exclude_rules: list | None = None,
    dump_menu_tree: bool = False,
    menu_tree_only: bool = False
):
    """æ‰§è¡Œçˆ¬è™«è„šæœ¬ç”Ÿæˆæµç¨‹ï¼ˆå¢å¼ºç‰ˆï¼‰"""

    launcher = None
    browser = None

    try:
        # 1. å¯åŠ¨Chrome
        console.print("\n[yellow]ğŸŒ æ­£åœ¨å¯åŠ¨Chromeæµè§ˆå™¨...[/yellow]")

        launcher = ChromeLauncher(
            debug_port=config.cdp_debug_port,
            user_data_dir=config.cdp_user_data_dir,
            headless=False,
            auto_select_port=config.cdp_auto_select_port
        )
        launcher.launch()
        console.print("[green]âœ“ Chromeå¯åŠ¨æˆåŠŸ[/green]")

        # 2. è¿æ¥æµè§ˆå™¨
        console.print("\n[yellow]ğŸ”— æ­£åœ¨è¿æ¥æµè§ˆå™¨...[/yellow]")

        browser = BrowserController(
            cdp_url=launcher.get_ws_endpoint(),
            timeout=config.cdp_timeout
        )
        await browser.connect()
        console.print("[green]âœ“ æµè§ˆå™¨è¿æ¥æˆåŠŸ[/green]")

        # 3. æ‰“å¼€ç›®æ ‡é¡µé¢
        console.print(f"\n[yellow]ğŸ“„ æ­£åœ¨æ‰“å¼€ç›®æ ‡é¡µé¢...[/yellow]")
        console.print(f"   URL: {url}")

        success, error_msg = await browser.open(url)
        if not success:
            raise RuntimeError(f"æ— æ³•æ‰“å¼€ç›®æ ‡é¡µé¢: {error_msg}")

        console.print("[green]âœ“ é¡µé¢åŠ è½½å®Œæˆ[/green]")

        # 4. æ»šåŠ¨é¡µé¢ä»¥è§¦å‘æ‡’åŠ è½½
        console.print("\n[yellow]ğŸ“œ æ­£åœ¨æ»šåŠ¨é¡µé¢ä»¥åŠ è½½æ›´å¤šå†…å®¹...[/yellow]")
        await browser.scroll_page(times=3)
        console.print("[green]âœ“ é¡µé¢æ»šåŠ¨å®Œæˆ[/green]")

        # 5. åŸºç¡€é¡µé¢åˆ†æ
        console.print("\n[yellow]ğŸ” æ­£åœ¨åˆ†æé¡µé¢ç»“æ„...[/yellow]")

        page_info = await browser.get_page_info()
        page_html = await browser.get_full_html()
        page_structure = await browser.analyze_page_structure()
        network_requests = browser.get_captured_requests()

        console.print(f"   é¡µé¢æ ‡é¢˜: {page_info.get('title', 'æœªçŸ¥')}")
        console.print(f"   HTMLé•¿åº¦: {len(page_html):,} å­—ç¬¦")
        console.print(f"   æ•è·è¯·æ±‚: {len(network_requests.get('all_requests', []))} ä¸ª")
        console.print(f"   APIè¯·æ±‚: {len(network_requests.get('api_requests', []))} ä¸ª")

        tables = page_structure.get("tables", [])
        lists = page_structure.get("lists", [])
        links = page_structure.get("links", {})

        console.print(f"   æ£€æµ‹åˆ°è¡¨æ ¼: {len(tables)} ä¸ª")
        console.print(f"   æ£€æµ‹åˆ°åˆ—è¡¨: {len(lists)} ä¸ª")
        console.print(f"   PDF/ä¸‹è½½é“¾æ¥: {len(links.get('pdfLinks', []))} ä¸ª")

        console.print("[green]âœ“ åŸºç¡€é¡µé¢åˆ†æå®Œæˆ[/green]")

        # 6. ã€å¢å¼ºåŠŸèƒ½ã€‘æ‰§è¡Œæ·±åº¦é¡µé¢åˆ†æ
        console.print("\n[yellow]ğŸ”¬ æ­£åœ¨æ‰§è¡Œå¢å¼ºé¡µé¢åˆ†æ...[/yellow]")
        console.print("   [å¢å¼ºåŠŸèƒ½] æ£€æµ‹æ•°æ®åŠ è½½çŠ¶æ€ã€äº¤äº’æ¢æµ‹ã€å‚æ•°åˆ†æ")
        
        # Step 1: æšä¸¾ç›®å½•æ ‘ï¼ˆä¸æŠ“åŒ…ï¼‰
        menu_tree = await browser.enumerate_menu_tree(max_depth=3)
        root = menu_tree.get("root")
        leaf_paths = menu_tree.get("leaf_paths", []) or []

        if dump_menu_tree:
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_dir = config.output_dir
            output_dir.mkdir(parents=True, exist_ok=True)
            menu_path = output_dir / f"menu_tree_{ts}.json"
            with open(menu_path, "w", encoding="utf-8") as f:
                json.dump({"url": url, "root": root, "leaf_paths": leaf_paths}, f, ensure_ascii=False, indent=2)
            console.print(f"[cyan]   å·²å¯¼å‡ºç›®å½•æ ‘: {menu_path}ï¼ˆleaf_paths={len(leaf_paths)}ï¼‰[/cyan]")

        # å¦‚æœåªæƒ³è¦ç›®å½•æ ‘å°±åˆ°æ­¤ç»“æŸ
        if menu_tree_only:
            console.print("[green]âœ“ å·²å®Œæˆç›®å½•æ ‘æšä¸¾ï¼ˆæŒ‰éœ€é€‰æ‹©åå¯å†ç”Ÿæˆè„šæœ¬ï¼‰[/green]")
            return True

        # Step 2: è§£æé€‰æ‹©è§„åˆ™ï¼ˆé¢å¤–éœ€æ±‚ + CLIï¼‰
        req_rules = _parse_menu_select(requirements)
        include_all = (include_rules or []) + req_rules.get("include", [])
        exclude_all = (exclude_rules or []) + req_rules.get("exclude", [])

        selected_leaf_paths = _filter_leaf_paths(leaf_paths, include_all, exclude_all)
        console.print(f"   ç›®å½•å¶å­æ€»æ•°: {len(leaf_paths)}ï¼Œæœ¬æ¬¡é€‰ä¸­: {len(selected_leaf_paths)}")
        if include_all:
            console.print(f"   include: {include_all[:5]}{'...' if len(include_all)>5 else ''}")
        if exclude_all:
            console.print(f"   exclude: {exclude_all[:5]}{'...' if len(exclude_all)>5 else ''}")

        # Step 3: åªå¯¹é€‰ä¸­å¶å­æŠ“åŒ…è¿˜åŸå‚æ•°ï¼ˆå¯ä¿¡æ˜ å°„ï¼‰
        console.print("   æ­£åœ¨å¯¹é€‰ä¸­ç›®å½•æŠ“åŒ…è¿˜åŸå‚æ•°ï¼ˆä»…é€‰ä¸­é¡¹ï¼‰...")
        verified_mapping = await browser.capture_mapping_for_leaf_paths(selected_leaf_paths)

        # ä»ç„¶ä¿ç•™ enhanced_analysis ç»™ LLMï¼ˆä½†åˆ†ç±»æ˜ å°„ä»¥ verified_mapping ä¸ºå‡†ï¼‰
        enhanced_analysis = await browser.enhanced_page_analysis()
        enhanced_analysis["menu_tree"] = {"root": root, "leaf_paths": leaf_paths}
        enhanced_analysis["selected_leaf_paths"] = selected_leaf_paths
        enhanced_analysis["verified_category_mapping"] = verified_mapping
        
        # æ˜¾ç¤ºå¢å¼ºåˆ†æç»“æœ
        data_status = enhanced_analysis.get("data_status", {})
        has_data = data_status.get("hasData", False)
        table_rows = data_status.get("tableRowCount", 0)
        list_items = data_status.get("listItemCount", 0)
        menus = data_status.get("potentialMenus", [])
        
        console.print(f"   æ•°æ®çŠ¶æ€: {'âœ“ æœ‰æ•°æ®' if has_data else 'âš  æ— æ•°æ®ï¼ˆéœ€è¦äº¤äº’ï¼‰'}")
        console.print(f"   è¡¨æ ¼æ•°æ®è¡Œ: {table_rows}, åˆ—è¡¨é¡¹: {list_items}")
        console.print(f"   æ£€æµ‹åˆ°èœå•é¡¹: {len(menus)} ä¸ª")
        
        # æ˜¾ç¤ºåˆ†ç±»å‚æ•°åˆ†æç»“æœ
        param_analysis = enhanced_analysis.get("param_analysis", {})
        category_params = param_analysis.get("category_params", [])
        if category_params:
            console.print(f"   [bold yellow]âš  è¯†åˆ«åˆ°åˆ†ç±»å‚æ•°: {len(category_params)} ä¸ª[/bold yellow]")
            for cat in category_params[:3]:
                console.print(f"      - {cat.get('param_name')}: {cat.get('sample_values', [])[:3]}")
        
        # æ˜¾ç¤ºå»ºè®®
        recommendations = enhanced_analysis.get("recommendations", [])
        if recommendations:
            console.print("   [yellow]ç³»ç»Ÿå»ºè®®:[/yellow]")
            for rec in recommendations:
                console.print(f"      âš ï¸ {rec}")
        
        console.print("[green]âœ“ å¢å¼ºé¡µé¢åˆ†æå®Œæˆ[/green]")

        # 7. è°ƒç”¨LLMç”Ÿæˆçˆ¬è™«è„šæœ¬
        console.print("\n[yellow]ğŸ¤– æ­£åœ¨è°ƒç”¨LLMç”Ÿæˆçˆ¬è™«è„šæœ¬...[/yellow]")
        console.print(f"   æ¨¡å‹: {config.qwen_model}")
        console.print("   è¿™å¯èƒ½éœ€è¦20-60ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…...")

        llm = LLMAgent(
            api_key=config.qwen_api_key,
            model=config.qwen_model,
            base_url=config.qwen_base_url,
            enable_auto_repair=config.llm_auto_repair
        )

        script_code = llm.generate_crawler_script(
            page_url=url,
            page_html=page_html,
            page_structure=page_structure,
            network_requests=network_requests,
            user_requirements=requirements if requirements else None,
            start_date=start_date,
            end_date=end_date,
            enhanced_analysis=enhanced_analysis  # ä¼ å…¥å¢å¼ºåˆ†æç»“æœ
        )

        # 7.5 ç”Ÿæˆååå¤„ç†
        # æ³¨æ„ï¼šHTTP éŸ§æ€§å±‚ã€æ—¥æœŸæå–å·¥å…·ã€è„†å¼±é€‰æ‹©å™¨ä¿®å¤å·²ç§»è‡³ llm_agent.py ä¸­çš„æ¡ä»¶æ€§åå¤„ç†
        # è¿™é‡Œåªä¿ç•™ç”¨æˆ·æŒ‡å®šçš„æ—¥æœŸèŒƒå›´å’Œåˆ†ç±»æ˜ å°„æ³¨å…¥
        if config.llm_auto_repair:
            # 7.6 ç”Ÿæˆååå¤„ç†ï¼šå¼ºåˆ¶æ³¨å…¥æ—¥æœŸ / å¯ä¿¡åˆ†ç±»æ˜ å°„ï¼ˆé˜²æ­¢æ¨¡å‹å¹»è§‰ï¼‰ + ç¦ç”¨åç»­ç¡¬ç¼–ç æ—¥æœŸè¦†ç›–
            script_code = _inject_selected_categories_and_fix_dates(
                script_code=script_code,
                start_date=start_date,
                end_date=end_date,
                verified_mapping=verified_mapping
            )
        else:
            console.print("[yellow]âš  å·²å…³é—­è‡ªåŠ¨ä¿®å¤/åå¤„ç†ï¼ˆllm.auto_repair=falseï¼‰ï¼šå°†ç›´æ¥ä¿å­˜ LLM åŸå§‹ç”Ÿæˆä»£ç [/yellow]")

        token_usage = llm.get_token_usage()
        console.print(f"   Tokenä½¿ç”¨: {token_usage['total_tokens']:,} (è¾“å…¥: {token_usage['prompt_tokens']:,}, è¾“å‡º: {token_usage['completion_tokens']:,})")
        console.print("[green]âœ“ è„šæœ¬ç”Ÿæˆå®Œæˆ[/green]")

        # 8. ä¿å­˜è„šæœ¬
        output_dir = config.output_dir
        output_dir.mkdir(parents=True, exist_ok=True)

        output_path = output_dir / output_name

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(script_code)

        console.print(f"\n[bold green]ğŸ‰ çˆ¬è™«è„šæœ¬å·²ç”Ÿæˆï¼[/bold green]")
        console.print(f"   ä¿å­˜è·¯å¾„: {output_path}")
        console.print(f"   æ–‡ä»¶å¤§å°: {len(script_code):,} å­—ç¬¦")

        # 9. æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        if RICH_AVAILABLE:
            console.print(Panel.fit(
                f"""[bold]ä½¿ç”¨æ–¹æ³•ï¼š[/bold]

1. è¿›å…¥è„šæœ¬ç›®å½•ï¼š
   [cyan]cd {output_dir}[/cyan]

2. å®‰è£…ä¾èµ–ï¼ˆå¦‚éœ€è¦ï¼‰ï¼š
   [cyan]pip install requests beautifulsoup4[/cyan]
   æˆ–
   [cyan]pip install playwright && playwright install chromium[/cyan]

3. è¿è¡Œè„šæœ¬ï¼š
   [cyan]python {output_name}[/cyan]
""",
                title="[bold cyan]ä¸‹ä¸€æ­¥[/bold cyan]",
                border_style="cyan"
            ))
        else:
            print("\n" + "=" * 50)
            print("ä½¿ç”¨æ–¹æ³•ï¼š")
            print(f"1. cd {output_dir}")
            print("2. pip install requests beautifulsoup4")
            print(f"3. python {output_name}")
            print("=" * 50)

        return True

    except Exception as e:
        console.print(f"\n[bold red]âŒ ç”Ÿæˆå¤±è´¥: {e}[/bold red]")
        import traceback
        console.print(traceback.format_exc())
        return False

    finally:
        # æ¸…ç†èµ„æº
        if browser:
            await browser.disconnect()
        if launcher:
            launcher.terminate()


async def main():
    """ä¸»å‡½æ•°"""
    print_banner()

    try:
        # 1. åŠ è½½é…ç½®
        console.print("\n[yellow]ğŸ“„ æ­£åœ¨åŠ è½½é…ç½®...[/yellow]")
        config = Config()
        console.print("[green]âœ“ é…ç½®åŠ è½½æˆåŠŸ[/green]")

        # 2. è·å–ç”¨æˆ·è¾“å…¥ï¼ˆæ”¯æŒå‘½ä»¤è¡Œå‚æ•°ï¼Œä¸”å‘½ä»¤è¡Œæ¨¡å¼é»˜è®¤éäº¤äº’ï¼‰
        parser = argparse.ArgumentParser(prog="pygen", add_help=True)
        parser.add_argument("url", nargs="?", help="ç›®æ ‡åˆ—è¡¨é¡µURL")
        parser.add_argument("start_date", nargs="?", default="2026-01-01", help="å¼€å§‹æ—¥æœŸ YYYY-MM-DD")
        parser.add_argument("end_date", nargs="?", default="2026-12-31", help="ç»“æŸæ—¥æœŸ YYYY-MM-DD")
        parser.add_argument("--requirements", default="", help="é¢å¤–éœ€æ±‚ï¼ˆå¯é€‰ï¼‰")
        parser.add_argument("--output", default="crawler.py", help="è¾“å‡ºè„šæœ¬æ–‡ä»¶åï¼ˆé»˜è®¤ crawler.pyï¼‰")
        parser.add_argument("--include", action="append", default=[], help="èœå•é€‰æ‹© include è§„åˆ™ï¼ˆå¯é‡å¤ï¼‰")
        parser.add_argument("--exclude", action="append", default=[], help="èœå•é€‰æ‹© exclude è§„åˆ™ï¼ˆå¯é‡å¤ï¼‰")
        parser.add_argument("--dump-menu-tree", action="store_true", help="å¯¼å‡ºç›®å½•æ ‘ JSON åˆ° output/ ç›®å½•")
        parser.add_argument("--menu-tree-only", action="store_true", help="åªæšä¸¾/å¯¼å‡ºç›®å½•æ ‘ï¼Œä¸ç”Ÿæˆè„šæœ¬")
        parser.add_argument("-y", "--yes", action="store_true", help="å‘½ä»¤è¡Œæ¨¡å¼ä¸‹è·³è¿‡ç¡®è®¤ï¼Œç›´æ¥å¼€å§‹")
        args, _ = parser.parse_known_args()

        if args.url:
            url = args.url
            if not url.startswith("http"):
                url = "https://" + url

            output_name = args.output
            if not output_name.endswith(".py"):
                output_name += ".py"

            user_input = {
                "url": url,
                "start_date": args.start_date,
                "end_date": args.end_date,
                "requirements": args.requirements,
                "output_name": output_name,
            }
            cli_mode = True
        else:
            user_input = get_user_input()
            cli_mode = False

        # 3. æ˜¾ç¤ºä»»åŠ¡ä¿¡æ¯
        if RICH_AVAILABLE:
            console.print("\n")
            console.print(Panel.fit(
                f"""[bold]ç”Ÿæˆä»»åŠ¡ç¡®è®¤ï¼š[/bold]

ğŸŒ ç›®æ ‡URLï¼š[cyan]{user_input['url']}[/cyan]
ğŸ“… æ—¶é—´èŒƒå›´ï¼š[cyan]{user_input['start_date']} ~ {user_input['end_date']}[/cyan]
ğŸ“ é¢å¤–éœ€æ±‚ï¼š[cyan]{user_input['requirements'] or 'ï¼ˆæ— ï¼‰'}[/cyan]
ğŸ“„ è¾“å‡ºæ–‡ä»¶ï¼š[cyan]{user_input['output_name']}[/cyan]
""",
                title="[bold cyan]PyGen[/bold cyan]",
                border_style="cyan"
            ))
        else:
            print("\n" + "-" * 50)
            print(f"ç›®æ ‡URL: {user_input['url']}")
            print(f"æ—¶é—´èŒƒå›´: {user_input['start_date']} ~ {user_input['end_date']}")
            print(f"é¢å¤–éœ€æ±‚: {user_input['requirements'] or 'ï¼ˆæ— ï¼‰'}")
            print(f"è¾“å‡ºæ–‡ä»¶: {user_input['output_name']}")
            print("-" * 50)

        # 4. ç¡®è®¤æ‰§è¡Œï¼ˆå‘½ä»¤è¡Œæ¨¡å¼é»˜è®¤éäº¤äº’ï¼Œé™¤éæ˜¾å¼ä¸ä¼  -y ä¸”ä¸ºäº¤äº’ç¯å¢ƒï¼‰
        if cli_mode:
            if not args.yes:
                console.print("[yellow]æç¤ºï¼šå‘½ä»¤è¡Œæ¨¡å¼å»ºè®®åŠ  -y è·³è¿‡ç¡®è®¤ï¼ˆä¾‹å¦‚ï¼špython main.py <url> <start> <end> -y --output xxx.pyï¼‰[/yellow]")
                console.print("[yellow]æœ¬æ¬¡æœªåŠ  -yï¼Œä¸ºé¿å…å¡åœ¨äº¤äº’è¾“å…¥ï¼Œå·²è‡ªåŠ¨ç»§ç»­æ‰§è¡Œã€‚[/yellow]")
        else:
            if RICH_AVAILABLE:
                if not Confirm.ask("\næ˜¯å¦å¼€å§‹ç”Ÿæˆï¼Ÿ", default=True):
                    console.print("[yellow]å·²å–æ¶ˆæ“ä½œ[/yellow]")
                    return
            else:
                confirm = input("\næ˜¯å¦å¼€å§‹ç”Ÿæˆï¼Ÿ[Y/n]: ")
                if confirm.lower() == 'n':
                    print("å·²å–æ¶ˆæ“ä½œ")
                    return

        # å¼€å§‹è®¡æ—¶
        start_time = time.time()

        # 5. æ‰§è¡Œç”Ÿæˆ
        success = await run_generation(
            url=user_input['url'],
            requirements=user_input['requirements'],
            output_name=user_input['output_name'],
            config=config,
            start_date=user_input['start_date'],
            end_date=user_input['end_date'],
            include_rules=getattr(args, "include", []) if cli_mode else None,
            exclude_rules=getattr(args, "exclude", []) if cli_mode else None,
            dump_menu_tree=getattr(args, "dump_menu_tree", False) if cli_mode else False,
            menu_tree_only=getattr(args, "menu_tree_only", False) if cli_mode else False
        )

        # è®¡ç®—è€—æ—¶
        elapsed_time = time.time() - start_time

        if success:
            console.print("\n[bold green]âœ… ä»»åŠ¡å®Œæˆï¼[/bold green]")
            console.print(f"[cyan]â±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f} ç§’[/cyan]")
        else:
            console.print("\n[bold red]âŒ ä»»åŠ¡å¤±è´¥[/bold red]")
            console.print(f"[cyan]â±ï¸  è€—æ—¶: {elapsed_time:.2f} ç§’[/cyan]")
            sys.exit(1)

    except FileNotFoundError as e:
        console.print(f"\n[bold red]é”™è¯¯ï¼š{e}[/bold red]")
        console.print("\nè¯·ç¡®ä¿é…ç½®æ–‡ä»¶å­˜åœ¨ï¼š")
        console.print("  - pygen/config.yaml")
        console.print("  - æˆ–é¡¹ç›®æ ¹ç›®å½•çš„ config.yaml")
        sys.exit(1)

    except ValueError as e:
        console.print(f"\n[bold red]é…ç½®é”™è¯¯ï¼š{e}[/bold red]")
        sys.exit(1)

    except KeyboardInterrupt:
        console.print("\n\n[yellow]ç”¨æˆ·ä¸­æ–­æ“ä½œ[/yellow]")
        sys.exit(0)

    except Exception as e:
        console.print(f"\n[bold red]å‘ç”Ÿé”™è¯¯ï¼š{e}[/bold red]")
        import traceback
        console.print(traceback.format_exc())
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
